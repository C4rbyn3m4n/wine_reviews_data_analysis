---
title: "Exploring and Analyizing Wine Enthusiast Reviews"
output: 
  html_notebook:
    toc: true
    toc_float: true
    theme: united
---
## Team members
**Saivamsi Hanumanthu** <br> [Vamso the Extraordinaire](mailto:shanumanthu4016@floridapoly.edu) 

**Osaki Pokima** <br> [**Saki-Saki**](mailto:student3@floridapoly.edu) 

**Isabel Zimmerman** <br> [**Z Best**](mailto:izimmerman5298@floridapoly.edu)

# Introduction
Turning 21 is a milestone in everyone's life and usually, people celebrate it with a family dinner and glass of wine. But, how does one find the best wine considering that person has never had alcohol. 

- Do they get the best rated/most expensive bottle? (Too bad college students are poor) 
- Do they try to find the best value wine? (Ballin' on a budget)

- Or do they follow Jess from New Girl? (Obviously, the only option)

Let's take a deep dive and answer these pressing questions!

Our project investigates ~120,000 wine reviews with characteristics such as variety, vintage, winery, price, etc. This is our Final Project for Intro to Data Science (Spring 2020) class, and we thought it was a bit too easy, so we decided to expand it and take it a step further.

# Prerequisites

Loading the required packages
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(scales)
```

# Dataset

Import processed data, which can be found [here](https://github.com/C4rbyn3m4n/wine_reviews_data_analysis/blob/master/data/processed_data/preprocessing.nb.html). Note: This file also credits our dataset curators and outlines our data cleaning pipeline.

```{r}
#read preprocessed data
wines <- read.csv(file = '../data/processed_data/wines.csv')
```

Get a sample of the dataset for easy testing. However, for our final report, we ran all of our code on the full wines dataset to get more accurate results.
```{r}
#set seed value to birthday of Ricardo Rodriguez, American wrestler and ring announcer and Dr. Reinaldo (Rei) Sanchez-Arias
set.seed(19630217)

#set percentage to test with for simplicity, if needed
percentage <- 5
wine_sample<- sample_n(wines, percentage/100*nrow(wines))
```

## Rating Classification

Wines are normally classified in categories as found on this [website](https://www.winemag.com/2010/04/09/you-asked-how-is-a-wines-score-determined/). To create a more rich dataset we added the field `rating_category` determined as:

|Category  | Rating  | Description                                            |
|----------|---------|--------------------------------------------------------|
|Classic   |	98-100 | The pinnacle of quality.                               |
|Superb    |	94-97	 | A great achievement.                                   |
|Excellent |	90-93	 | Highly recommended.                                    |
|Very Good |  87-89	 | Often good value; well recommended.                    |
|Good	     |  83-86	 | Suitable for everyday consumption; often good value.   |
|Acceptable|	80-82	 | Can be employed in casual, less-critical circumstances |

This allows to take a quantitative data and turn it into qualitative data, which can be used for data visualization later. 

```{r}
# function to add rating
rating_category <- function(points){
  if(points>=98){
    return("Classic")
  }
  else if (points>=94){
    return("Superb")
  }
  else if(points>=90){
    return("Excellent")
  }
  else if(points>=87){
    return("Very Good")
  }
  else if(points>=83){
    return("Good")
  }
  else{
    return("Acceptable")
  }
}

wines<- wines %>%
  rowwise() %>%
  mutate(rating_category = rating_category(points))
head(wines)
```
## Create a Reviewer Profile
Each reviewer has there own bias. In order to offset that we made a "profile" for each reviewer. This profile allows us to later normalize the wine points for more robust apples to apples comparison.

### Split Taster Data
To make our dataframes more managable we split reduntant information about the tasters into a new dataframe.
```{r}
tasters <- wines %>%
  select(taster_name, taster_twitter_handle) %>% 
  unique()
tasters
```


Drop `taster_twitter_handle` in wines dataframe to reduce reduntant information.
```{r}
wines <- wines %>%
  select(-taster_twitter_handle)
head(wines)
```

### Create Reviewer Metrics
Each reviewers profile includes the following metrics to create a profile: 

- `avg_points` which is the average of all the reviewer's scores

- `sd_points` which is the standard deviation of all the reviewer's scores

- `var_points` which is the variance of all the reviewer's scores

- `reviews` which is the number of reviews conducted

```{r}
taster_rating_profile <- wines %>%
  group_by(taster_name) %>%
  summarize(
    avg_points = mean(points),
    sd_points = sd(points),
    var_points = var(points),
    reviews = n()
  )

tasters <- inner_join(tasters, taster_rating_profile, by = "taster_name")
head(tasters)
```


## Normalized Points
As mentioned, each reviewer has a different bias. To offset this, we created a normalized metric, `norm_points`, by looking at the number of standard deviations a wine is from the reviewer's `avg_points`. This gives us a more accurate representation of which wines are "better" than the rest.

```{r}
normalize_points <- function(data){
  left_join(data, tasters, by = "taster_name")%>%
    rowwise() %>%
    mutate(norm_points = (points-avg_points)/sd_points) %>%
    select(-avg_points, -sd_points, -var_points, -taster_twitter_handle, -reviews)
}

wines <- normalize_points(wines)
head(wines) 
```

## Data Sanitation
To ensure the integrity of our data, we perform some hard checks that could have been missed during our data pre-processing.
\
\
Vintage seems to have year 7200, so we filtered all data up to 2019
``` {r}
wines <- wines %>%
  filter(vintage<2019)
```

# Data Exploration
Before, conducting any detailed analysis of our dataset, we looked at a quick summary of the dataset
```{r}
summary(wines)
```

## Univariate Exploration
To better understand the distribution of our data, we did some simple univariate visualization based on specific fields. Additionally, before doing a multivariate analysis and answering our research questions, we first want to ensure our dataset is robust and an accurate representation of the real world.

### Alcohol Amount
The visualization below depicts the distribution of our dataset based on alcohol percentage, `alcohol`. To better understand and visualize the data, we categorized the graph based on `rating_category`. Notice, a majority of wines have an alcohol amount between 12%-15%, and according to [Real Simple](https://www.realsimple.com/holidays-entertaining/entertaining/food-drink/alcohol-content-wine), wine alcoholic content averages between 11%-13%. This leads us to believe our data is an accurate representation of the real world.
```{r}
wines %>% 
  group_by(alcohol) %>% 
  ggplot() +
  geom_histogram(
    mapping = aes(
      x = alcohol, 
      fill = rating_category),
    na.rm = TRUE,
    bins = 50) +
  scale_x_continuous(
    breaks = seq(0,25,1), 
    limits = c(4,22)) +
  labs(
    title = "Distribution of Alcohol Percentage",
    x = "Alcohol Percentage",
    y = "Count",
    fill = "Rating Category"
  )
```

### Vintage
Next, we wanted to see what vintage most of the wines in the dataset were. Again to better understand and visualize the data, we categorized the graph based on `rating_category`. Notice that there is roughly an equal percentage of each rating category per vintage.

(Note: Data points before 1990 have been omitted for clarity in visualization)
```{r}
wines %>%
  ggplot() +
  geom_bar(
    mapping = aes(
      x=vintage, 
      fill = rating_category),
    na.rm = TRUE) +
  scale_x_continuous(
    breaks = seq(1990,2019,5), 
    limits = c(1990,2019)) +
  labs(
    title = "Distribution of Vintage",
    x = "Vintage", 
    y = "Count",
    fill = "Rating Category")
```

### Winery
To better understand the number wines per winery, we did a visualization that counts the number of wines per winery showing only Top 10 wineries to give you an idea of what winery has the most selection of wines. Notice, each of the top 10 producers of wine have over 100 different wine labels.
```{r}
wines %>%
  group_by(winery) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1:10) %>%
  ggplot() +
  geom_col(
    mapping = aes(
      x= reorder(winery, count),
      y = count,
      fill = winery)) +
  labs(
    title = "Distribution of Winery (Top 10)",
    x = "Winery", 
    y = "Count") +
  theme(legend.position = "none") +
  coord_flip()
```

### Province
To better understand the number of wines per province, we did a visualization that counts the number of wines per province, showing only the top 10 provinces with the most wines. This can give the reader an idea where their wine will most likely be made with California standing out as a clear leader.
```{r}
wines %>% 
  group_by(province) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>% 
  slice(1:10) %>% 
  ggplot()+
  geom_col(
    mapping = aes(
      x = reorder(province, count), 
      y = count,
      fill = province)) +
  labs(
    title = "Distribution of Province (Top 10)",
    x = "Province", 
    y = "Count") +
  theme(legend.position = "none") +
  coord_flip()
```
### Wine Category
Next, we wanted to visualize the distribution of different wine categories in our dataset. To better understand and visualize the data, we categorized the graph based on `rating_category`. Notice, a majority of the wines are red or white wines.

```{r}
wines %>% 
  ggplot()+
  geom_bar(
    mapping = aes(
      x = category,
      fill = rating_category)) +
  labs(
    title = "Distribution of Wine Category",
    x = "Wine Category", 
    y = "Count",
    fill = "Rating Category") +
  coord_flip()
```

### Price
Next, we wanted to visualize the distribution of price in our dataset. To better understand and visualize the data, we categorized the graph based on `rating_category`. Notice, a majority of wines are \$50 and below, with the most common being between \$12 - \$25. Again, this accurately represents the real world. As stated by [Vivino](https://www.vivino.com/wine-news/how-much-does-a-good-bottle-of-wine-cost), the average price for a good bottle of red/white wine is ~\$15 and ~\$28 for a very good bottle. (CAUTION: The Vivino prices denoted were simply an average for red/white wines average costs. This was done to generalize the information to make a simple comparison. Also, this limited to red/white wine and does not accurately include other types, which are included within our dataset)

(Note: Data points above $400 have been omitted for clarity in visualization)
```{r}
wines %>% 
  filter(price < 400) %>% 
  ggplot() +
  geom_histogram(
    mapping = aes(
      x=price, 
      fill = rating_category),
    binwidth = 15) +
  labs(
    title = "Distribution of Price",
    x = "Price", 
    y = "Count",
    fill = "Rating Category")
```

###  Points 
Next, we wanted to visualize the distribution of points in our dataset. Notice, here that a majority of wines receive a score between 87 and 90. Which is accurate to the information provided on [Wine Searcher]("https://www.wine-searcher.com/critics-17-wine+enthusiast"), which states 50% of the scores fall between 86-90 point from Wine Enthusiast ratings.

(Note: We our dataset was reterived from the Wine Enthusiast website)
```{r}
wines %>%
  ggplot() +
  geom_histogram(
    mapping = aes(x=points),
    bins = 20)+
  labs(
    title = "Distribution of Points",
    x = "Points", 
    y = "Count")
```

## Multivariate Exploration
Now that we have a better understanding of our data, and we know it is an accurate representation of the real world, we can perform a more detailed analysis using multiple variables.

### Points by Taster
To understand the point distribution by tasters, we did a multivariate visualization that correlates taster names based on the average wine points as identified by the x-intercept. This gives the reader an idea of how some reviewers correlate to the overall average.

(Note: The “blank” represents unknown reviewers. We assumed the reviewers not named have not rated a significant amount of wines and can be grouped into a singular reviewer)
```{r}
wines %>%
  ggplot() +
  geom_boxplot(
    mapping = aes(
      x=taster_name,
      y=points, 
      color = taster_name)) +
  geom_hline(yintercept = mean(wines$points)) +
  theme(legend.position = "none")+
  labs(
    title = "Points by Taster",
    x="Taster Name",
    y="Points"
  )+
  coord_flip()
```


### Price by Points
To understand the price distribution by points, we did a multivariate visualization that creates a scatter plot of the wines based on points and price. Then, we added a smooth transformation to identify trends. Notice, the data is stacked, and the scores range from 80-100
```{r}
wines %>% 
  ggplot() +
  geom_point(
    mapping = aes(
      x = points, 
      y = price, 
      color = category),
    na.rm = TRUE,
    alpha = 0.2) +
  labs(
    title = "Price by Points", 
    x = "Points",
    y = "Price",
    color = "Wine Category") +
  geom_smooth(
    mapping = aes(
      x = points, 
      y = price),
    na.rm = TRUE)
```

Since there are multiple outliers, and the visualization is clustered. By performing a log on all the prices, we can reduce the skewness of the visualization. Notice, as the quality of wine increases, price increases exponentially.
```{r}
wines %>% 
  ggplot() +
  geom_point(
    mapping = aes(
      x = points, 
      y = log(price), 
      color = category),
    na.rm = TRUE,
    alpha = 0.2) +
  labs(
    title = "log(Price) by Points", 
    x = "Points",
    y = "log(Price)",
    color = "Wine Category") +
  geom_smooth(
    mapping = aes(
      x = points, 
      y = log(price)),
    na.rm = TRUE)
```

#### Group by Wine Category
Next, our group wanted to do a more granular analysis by looking at how the price varies by points grouped by the wine category. Notice, all the prices go up as points go up, but the growth rates are different per wine category.
```{r}
wines %>% 
  ggplot() +
  geom_point(
    mapping = aes(
      x = points, 
      y = log(price), 
      color = category),
    alpha =0.2,
    na.rm = TRUE) +
  geom_smooth(
    mapping = aes(
      x = points, 
      y = log(price)),
    na.rm = TRUE) +
  facet_wrap(~category) +
  labs(
    title = "log(Price) by Points", 
    x = "Points",
    y = "log(Price)")+
  theme_minimal()+
  theme(legend.position = "none" )
```


# Data Analysis
Now that we fully understand the dataset we are working with, we plan to answer some research questions proposed by the team.

## What is the best wine?
An easy way to determine the best wine is by simply finding the top 10 wines by rating.
```{r}
wines %>%
  arrange(desc(points)) %>%
  slice(1:10) %>%
  select(title,price, points,rating_category, norm_points)
```

However, this does not account for the taster's bias. Instead, our group normalized the points based on each taster based on the number of standard deviations a wine is from the raters average. For example, Taster A could give a wine 100 but has an average rating score of 95 with a standard deviation of 5. Whereas, Taster B could offer a wine 91 and have an average score of 87 with a standard deviation of 2. Although the wine tasted by Taster A got a perfect 100 score, Taster B’s wine was much “better” wine since it was two standard deviations from the tasters average compared to 1 standard deviation of the other wine.

Looking at the `norm_points` these are the top 10 best wines
```{r}
wines %>%
  arrange(desc(norm_points)) %>%
  slice(1:10)%>%
  select(title,price, points,rating_category, norm_points)
```

## What is the best value wine?
A simple value metric we can use to determine best value is `points/price`.
```{r}
wines %>%
  arrange(desc(points/price)) %>%
  slice(1:10)%>%
  select(title,price, points,rating_category, norm_points)
```

However, again this metric is not normalized. Instead, `norm_points/price` would yield more robust results.
```{r}
wines %>%
  arrange(desc(norm_points/price)) %>%
  slice(1:10) %>%
  select(title,price, points,rating_category, norm_points)
```

## Which province has the best wine?
To determine the best province for wine by points, we averaged the points of all wines per province with a sample size greater than 30 and returned the top 10 with standard error. Notice how the standard error is low, meaning the spread of our data is also small, and the average is very accurate.

```{r}
wines %>% 
  group_by(province) %>%
  summarise(
    avg_points_prov = mean(points), 
    count = n(), 
    std_err_points_prov = sd(points)/sqrt(count)) %>%
  filter(count>30) %>%
  arrange(desc(avg_points_prov)) %>%
  slice(1:10) %>%
  ggplot() +
  geom_col(
    mapping = aes(
      x = reorder(province,avg_points_prov), 
      y = avg_points_prov,
      fill = province)) +
   geom_errorbar(
    mapping = aes(
      x = province,
      y = avg_points_prov,
      ymin = avg_points_prov - std_err_points_prov, 
      ymax = avg_points_prov + std_err_points_prov
      ),
    width = 0.2)+
  scale_y_continuous(
    limits=c(85,95), 
    oob = rescale_none)+
  labs(
      x = 'Province', 
      y = "Average Points", 
      title = "Average Points By Province (Top 10)") +
  theme(legend.position = "none")+
  coord_flip()
```

## Which wine variety is the best?
To determine the best variety of wine, we use the average points of all wines per variety with a sample size greater than 30. The graph below shows the top 10 varieties with their respective standard error.

```{r}
wines %>% 
  group_by(variety) %>%
  summarise(
    avg_points_variety = mean(points), 
    count = n(), 
    std_err_points_variety = sd(points)/sqrt(count)) %>%
  filter(count>30) %>%
  arrange(desc(avg_points_variety)) %>%
  slice(1:10) %>%
  ggplot() +
  geom_col(
    mapping = aes(
      x = reorder(variety,avg_points_variety), 
      y = avg_points_variety,
      fill = variety)) +
   geom_errorbar(
    mapping = aes(
      x = variety,
      y = avg_points_variety,
      ymin = avg_points_variety - std_err_points_variety, 
      ymax = avg_points_variety + std_err_points_variety
      ),
    width = 0.2)+
  scale_y_continuous(
    limits=c(85,95), 
    oob = rescale_none)+
  labs(
      x = 'Variety', 
      y = "Average Points", 
      title = "Average Points By Variety (Top 10)") +
  theme(legend.position = "none")+
  coord_flip()
```

## Jess from New Girl’s favorite wine?
Sounds like a silly question, but take a closer look and you'll find an interesting question within it: "Can we determine the best value wine based on how much people are willing to pay?"  WE SURE CAN!

```{r}
# If you want to get user input
#user_price <- readline(prompt = "How much are you willing to spend on a bottle?")
#user_price <- as.integer(user_price)
user_price<-11

wines %>% 
  filter(price <= user_price) %>%
  arrange(desc(norm_points/price)) %>%
  slice(1:10) %>%
  select(title, price, points,rating_category, norm_points)
```

Now back to the orignal question with Jess
<br>
<div style="width:100%;height:0;padding-bottom:61%;position:relative;"><iframe src="https://giphy.com/embed/3osxY3Ju6p2jJbBo88" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>

```{r} 
wines %>% 
  filter(price < 11) %>%
  filter(category == "Sparkling") %>%
  filter(grepl("pink", title, ignore.case = T) == T) %>%
  select(title,price, points,rating_category, norm_points)
```
As you can see, "Yellow Tail 2015 Pink Bubbles Sparkling (South Australia)" is Jess's type of wine!

# Conclusion
After all this exploration, we were able to walk away with some insights. We learned that standardizing tasters gives a more accurate overview of what the best wines really are, that point values affect price, and that you're most likely drinking wine from California. In the end, though, this exploration of wine showed us more than just how to design the perfect flight; we learned the importance of data preprocessing, the power of mindful graphics, how to make every ggplot easy to understand for the reader using color, and the practicality of the pipe tool. We were able to apply data manipulation and exploration skills such as filtering, mutating, arranging, greping, and slicing data. Beyond R skills, we learned how to adapt to being a remote team, which was significantly helped with the utilization of GitHub. We feel this report gives a well-rounded display of the tools we were taught throughout the semester, and we were excited to build from that knowledge and integrate other tools as well.

# Future Works
There is undoubtedly more exploration to be done within this dataset. 
Integrating more Twitter data with packages such as `rtweet`, we could design the "perfect stereotype" of a wine connoisseur by gathering keywords from tweets. Delving into the text mining portion of data science, we could find popular words to describe a wine from each review and design artificial reviews. We could take the data we found, build statistical learning models such as a random forest to predict prices of wines based on the descriptions; this would be a useful model for new, budding (pun intended) wineries to determine the price. Additionally, this data is only a fraction of the data found on the Wine Enthusiast website. Overall, creativity is the only limitation on what other problems we could solve with this dataset.

The data used is just a fraction of the data found on the Wine Enthusiast website, the team has created a script to collect additional information on the site, which can be found [here](https://github.com/C4rbyn3m4n/wine_reviews_data_analysis/tree/master/data/scripts) for future expansion.

# Datasets Cited
Special thanks to [Zack Thoutt](https://www.kaggle.com/zynicide) for providing us with [dataset_1](https://www.kaggle.com/zynicide/wine-reviews) and [Sanyam Kapoor](https://github.com/activatedgeek) for providing us with  [dataset_2](https://github.com/activatedgeek/winemag-dataset).
 
The data we used is available at: [https://github.com/C4rbyn3m4n/wine_reviews_data_analysis/tree/master/data](https://github.com/C4rbyn3m4n/wine_reviews_data_analysis/tree/master/data)